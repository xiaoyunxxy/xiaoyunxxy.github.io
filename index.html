<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Xiaoyun Xu</title>

    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <!-- <h2>  
      <a href="#about">to about</a>  
      <a href="#services">to service</a>  
    </h2>  --> 


    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Xiaoyun Xu
                </p>
                <p id="about">
Hello! I’m a final-year PhD student in the Digital Security group at Radboud University, where I’m fortunate to be advised by Stjepan Picek. Before this, I earned my MSc in Advanced Computing from the University of Bristol and a BEng in Software Engineering from the University of Electronic Science and Technology of China. I also spent two years as a Research Assistant at ISCAS before starting my PhD. <br> <br> My research interests lie primarily in adversarial machine learning and designing robust and general defenses for risks in machine learning technologies. <br> <br> Outside of research, I enjoy seeing the world, exploring diverse cultures and local cuisines, and taking in landscapes.
                </p>
                <p style="text-align:center">
                  <a href="mailto:xiaoyun.xu@ru.nl">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=vPA0GgUAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/xiaoyunxxy/">Github</a> &nbsp;/&nbsp;
                  <a href="files/xxy_CV.pdf">CV</a>
                </p>
              </td>
              <td style="padding:4.5%;width:25%;max-width:25%">
                <a><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/xxy_photo.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
 

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
              </td>
            </tr>
          </tbody></table>


          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <tr bgcolor="#FFFFFF">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/weights_change.jpg" width="170">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2501.05928">
          <span class="papertitle">Towards Backdoor Stealthiness in Model Parameter Space</span>
        </a>
        <br>
        <strong>Xiaoyun Xu</strong>,
        <a>Zhuoran Liu</a>,
        <a>Stefanos Koffas</a>,
        <a>Stjepan Picek</a>
        <br>
        <em>ACM Conference on Computer and Communications Security (CCS)</em>, 2025, Accepted
        <br>
        <a href="https://github.com/xiaoyunxxy/parameter_backdoor">Code</a>
        /
        <a href="https://arxiv.org/abs/2501.05928">arXiv</a>
        <p></p>
      </td>
    </tr>

    <tr bgcolor="#FFFFFF">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/badnets_0.2.png" width="170">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://proceedings.neurips.cc/paper_files/paper/2024/hash/cfaccbd9b5e62562779351ebcb140c94-Abstract-Conference.html">
          <span class="papertitle">BAN: Detecting Backdoors Activated by Adversarial Neuron Noise</span>
        </a>
        <br>
        <strong>Xiaoyun Xu</strong>,
        <a>Zhuoran Liu</a>,
        <a>Stefanos Koffas</a>,
        <a>Shujian Yu</a>,
        <a>Stjepan Picek</a>
        <br>
        <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2024
        <br>
        <a href="https://github.com/xiaoyunxxy/ban">Code</a>
        /
        <a href="https://arxiv.org/abs/2405.19928">arXiv</a>
        <p></p>
      </td>
    </tr>

    <tr bgcolor="#FFFFFF">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/mimir.png" width="170">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2312.04960">
          <span class="papertitle">MIMIR: Masked Image Modeling for Mutual Information-based Adversarial Robustness</span>
        </a>
        <br>
        <strong>Xiaoyun Xu</strong>,
        <a>Shujian Yu</a>,
        <a>Zhuoran Liu</a>,
        <a>Stjepan Picek</a>
        <br>
        <em>Under review</em>
        <br>
        <a href="https://github.com/xiaoyunxxy/MIMIR">Code</a>
        /
        <a href="https://arxiv.org/abs/2312.04960">arXiv</a>
        <p></p>
      </td>
    </tr>


    <tr bgcolor="#FFFFFF">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/usb.png" width="170">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/abstract/document/10646976?casa_token=Mu4JR6tTcqwAAAAA:fBvq-XKknk57w2PFqU1ssx_YI5rFrSY4699V9ooKl7ylHM8AKCzc2fNzbj-yp1d-c9QI86GFlCPE">
          <span class="papertitle">Universal Soldier: Using universal adversarial perturbations for detecting backdoor attacks</span>
        </a>
        <br>
        <strong>Xiaoyun Xu</strong>,
        <a>Oguzhan Ersoy</a>,
        <a>Behrad Tajalli</a>,
        <a>Stjepan Picek</a>
        <br>
        <em>IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W)</em>, 2024
        <br>
        <a href="https://arxiv.org/abs/2302.00747">arXiv</a>
        <p></p>
      </td>
    </tr>


    <tr bgcolor="#FFFFFF">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/advmae.png" width="170">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://dl.acm.org/doi/10.1145/3576915.3624370">
          <span class="papertitle">Poster: Boosting Adversarial Robustness by Adversarial Pre-training</span>
        </a>
        <br>
        <strong>Xiaoyun Xu</strong>,
        <a>Stjepan Picek</a>
        <br>
        <em>ACM Conference on Computer and Communications Security (CCS)</em>, 2023
        <br>
        <p></p>
      </td>
    </tr>


    <tr bgcolor="#FFFFFF">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/ibrar.png" width="170">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/abstract/document/10207164?casa_token=tvmQ2K3SW8AAAAAA:5Pu3CSjEWvQoP_WPZ9ft92zYccVSSk4o5_W3W7H8DGrThKkU2ZjyQ93_LAcod1fhxn5nJdkI8qRF">
          <span class="papertitle">IB-RAR: Information Bottleneck as Regularizer for Adversarial Robustness</span>
        </a>
        <br>
        <strong>Xiaoyun Xu</strong>,
        <a>Guilherme Perin</a>,
        <a>Stjepan Picek</a>
        <br>
        <em>IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W)</em>, 2023
        <br>
        <a href="https://github.com/xiaoyunxxy/IB-RAR">Code</a>
        /
        <a href="https://arxiv.org/abs/2302.10896">arXiv</a>
        <p></p>
      </td>
    </tr>


    <tr bgcolor="#FFFFFF">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/informationleakage.png" width="170">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://dl.acm.org/doi/abs/10.1145/3411501.3419423?casa_token=KgpcuQHgUuoAAAAA:AHeBGC1SgnZI8oudy3OCaAyFavr_yk43Xf3Bboy1tlCpUe32_iogsZjyToJsXBPnAHJZQ0Yyv2eW">
          <span class="papertitle">Information leakage by model weights on federated learning</span>
        </a>
        <br>
        <strong>Xiaoyun Xu</strong>,
        <a>Jingzheng Wu</a>,
        <a>Mutian Yang</a>,
        <a>Tianyue Luo</a>,
        <a>Xu Duan</a>,
        <a>Weiheng Li</a>,
        <a>Yanjun Wu</a>,
        <a>Bin Wu</a>
        <br>
        <em>In Proceedings of the 2020 workshop on privacy-preserving machine learning in practice, CCS workshop PPLMP</em>, 2020
        <br>
        <p></p>
      </td>
    </tr>

          </tbody></table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2 id="services">Services:</h2>
                </td>
              </tr>
              <tr> <td style="padding-left:20px;">Reviewer: BMVC, ICLR, NeurIPS</td></tr>
              <tr> <td style="padding-left:20px;">External Reviewer: IEEE S&amp;P, NDSS, USENIX Security </td></tr>
            </tbody></table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Great template from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
