# Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CCS 2025</div><img src='images/weights_change.jpg' alt="sym" width="75%"></div></div>
<div class='paper-box-text' markdown="1">

[Towards Backdoor Stealthiness in Model Parameter Space](https://arxiv.org/abs/2501.05928)

**Xiaoyun Xu**, Zhuoran Liu, Stefanos Koffas, Stjepan Picek

ACM Conference on Computer and Communications Security (CCS), 2025

[**Code**](https://github.com/xiaoyunxxy/parameter_backdoor) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
[**arXiv**](https://arxiv.org/abs/2501.05928) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2024</div><img src='images/badnets_0.2.png' alt="sym" width="75%"></div></div>
<div class='paper-box-text' markdown="1">

[BAN: Detecting Backdoors Activated by Adversarial Neuron Noise](https://proceedings.neurips.cc/paper_files/paper/2024/hash/cfaccbd9b5e62562779351ebcb140c94-Abstract-Conference.html)

**Xiaoyun Xu**, Zhuoran Liu, Stefanos Koffas, Shujian Yu, Stjepan Picek

Advances in Neural Information Processing Systems (NeurIPS), 2024

[**Code**](https://github.com/xiaoyunxxy/ban) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
[**arXiv**](https://arxiv.org/abs/2405.19928) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arXiv</div><img src='images/mimir.png' alt="sym" width="75%"></div></div>
<div class='paper-box-text' markdown="1">

[MIMIR: Masked Image Modeling for Mutual Information-based Adversarial Robustness](https://arxiv.org/abs/2312.04960)

**Xiaoyun Xu**, Shujian Yu, Zhuoran Liu, Stjepan Picek

Under review

[**Code**](https://github.com/xiaoyunxxy/MIMIR) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
[**arXiv**](https://arxiv.org/abs/2312.04960) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">DSN 2024</div><img src='images/usb.png' alt="sym" width="75%"></div></div>
<div class='paper-box-text' markdown="1">

[Universal Soldier: Using universal adversarial perturbations for detecting backdoor attacks](https://ieeexplore.ieee.org/abstract/document/10646976?casa_token=Mu4JR6tTcqwAAAAA:fBvq-XKknk57w2PFqU1ssx_YI5rFrSY4699V9ooKl7ylHM8AKCzc2fNzbj-yp1d-c9QI86GFlCPE)

**Xiaoyun Xu**, Oguzhan Ersoy, Behrad Tajalli, Stjepan Picek

IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W), 2024

[**arXiv**](https://arxiv.org/abs/2302.00747) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CCS 2023</div><img src='images/advmae.png' alt="sym" width="75%"></div></div>
<div class='paper-box-text' markdown="1">

[Poster: Boosting Adversarial Robustness by Adversarial Pre-training](https://dl.acm.org/doi/10.1145/3576915.3624370)

**Xiaoyun Xu**, Stjepan Picek

ACM Conference on Computer and Communications Security (CCS), 2023

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">DSN 2023</div><img src='images/ibrar.png' alt="sym" width="75%"></div></div>
<div class='paper-box-text' markdown="1">

[IB-RAR: Information Bottleneck as Regularizer for Adversarial Robustness](https://ieeexplore.ieee.org/abstract/document/10207164?casa_token=tvmQ2K3SW8AAAAAA:5Pu3CSjEWvQoP_WPZ9ft92zYccVSSk4o5_W3W7H8DGrThKkU2ZjyQ93_LAcod1fhxn5nJdkI8qRF)

**Xiaoyun Xu**, Guilherme Perin, Stjepan Picek

IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W), 2023

[**Code**](https://github.com/xiaoyunxxy/IB-RAR) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
[**arXiv**](https://arxiv.org/abs/2302.10896) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CCS@PPLMP 2020</div><img src='images/informationleakage.png' alt="sym" width="75%"></div></div>
<div class='paper-box-text' markdown="1">

[Information leakage by model weights on federated learning](https://dl.acm.org/doi/abs/10.1145/3411501.3419423?casa_token=KgpcuQHgUuoAAAAA:AHeBGC1SgnZI8oudy3OCaAyFavr_yk43Xf3Bboy1tlCpUe32_iogsZjyToJsXBPnAHJZQ0Yyv2eW)

**Xiaoyun Xu**, Jingzheng Wu, Mutian Yang, Tianyue Luo, Xu Duan, Weiheng Li, Yanjun Wu, Bin Wu

In Proceedings of the 2020 workshop on privacy-preserving machine learning in practice, CCS workshop PPLMP, 2020
</div>
</div>